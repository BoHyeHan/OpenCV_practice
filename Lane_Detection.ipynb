{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-b9ecaeea664d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[1;31m#gray_img = grayscale(image) # 흑백이미지로 변환\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[0mblur_frame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgaussian_blur\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Blur 효과\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m         \u001b[0mcanny_frame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcanny\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblur_frame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m210\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Canny edge 알고리즘\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[0mvertices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m45\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m45\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-b9ecaeea664d>\u001b[0m in \u001b[0;36mcanny\u001b[1;34m(img, low_threshold, high_threshold)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcanny\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlow_threshold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhigh_threshold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# Canny 알고리즘\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCanny\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlow_threshold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhigh_threshold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgaussian_blur\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# 가우시안 필터\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# def grayscale(img): # 흑백이미지로 변환\n",
    "#     return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "def canny(img, low_threshold, high_threshold): # Canny 알고리즘\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "def gaussian_blur(img, kernel_size): # 가우시안 필터\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "def region_of_interest(img, vertices, color3=(255,255,255), color1=255): # ROI 셋팅\n",
    "\n",
    "    mask = np.zeros_like(img) # mask = img와 같은 크기의 빈 이미지\n",
    "    \n",
    "    if len(img.shape) > 2: # Color 이미지(3채널)라면 :\n",
    "        color = color3\n",
    "    else: # 흑백 이미지(1채널)라면 :\n",
    "        color = color1\n",
    "        \n",
    "    # vertices에 정한 점들로 이뤄진 다각형부분(ROI 설정부분)을 color로 채움 \n",
    "    cv2.fillPoly(mask, vertices, color)\n",
    "    \n",
    "    # 이미지와 color로 채워진 ROI를 합침\n",
    "    ROI_image = cv2.bitwise_and(img, mask)\n",
    "    return ROI_image\n",
    "\n",
    "def draw_lines(img, lines, color=[255, 0, 0], thickness=2): # 선 그리기\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            cv2.line(img, (x1, y1), (x2, y2), color, thickness)\n",
    "\n",
    "def draw_fit_line(img, lines, color=[255, 0, 0], thickness=10): # 대표선 그리기\n",
    "        cv2.line(img, (lines[0], lines[1]), (lines[2], lines[3]), color, thickness)\n",
    "\n",
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap): # 허프 변환\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    #line_img = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "    #draw_lines(line_img, lines)\n",
    "\n",
    "    return lines\n",
    "\n",
    "def weighted_img(img, initial_img, α=1, β=1., λ=0.): # 두 이미지 operlap 하기\n",
    "    return cv2.addWeighted(initial_img, α, img, β, λ)\n",
    "\n",
    "def get_fitline(img, f_lines): # 대표선 구하기   \n",
    "    lines = np.squeeze(f_lines)\n",
    "    lines = lines.reshape(lines.shape[0]*2,2)\n",
    "    rows,cols = img.shape[:2]\n",
    "    output = cv2.fitLine(lines,cv2.DIST_L2,0, 0.01, 0.01)\n",
    "    vx, vy, x, y = output[0], output[1], output[2], output[3]\n",
    "    x1, y1 = int(((img.shape[0]-1)-y)/vy*vx + x) , img.shape[0]-1\n",
    "    x2, y2 = int(((img.shape[0]/2+100)-y)/vy*vx + x) , int(img.shape[0]/2+100)\n",
    "    \n",
    "    result = [x1,y1,x2,y2]\n",
    "    return result\n",
    "\n",
    "#파일 불러오기\n",
    "cap=cv2.VideoCapture('C:/Python_Portfolio/BlackBox_data/MDR_180910_064606.AVI')\n",
    "#cap=cv2.VideoCapture('2018-02-16-17h-42m-28s_c2_normal.mp4')\n",
    "\n",
    "while True:\n",
    "    #영상 읽기\n",
    "    #ret : 읽히면 T 아니면 F\n",
    "    #frame : 영상 저장 버퍼\n",
    "    ret, frame = cap.read()\n",
    "    #print(ret)\n",
    "    if ret:\n",
    "        gray=cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        cv2.imshow('frame',gray)\n",
    "        \n",
    "        if cv2.waitKey(1)&0xFF==ord('q'):\n",
    "            break\n",
    "        height, width = frame.shape[:2] # 이미지 높이, 너비\n",
    "        #gray_img = grayscale(image) # 흑백이미지로 변환\n",
    "        blur_frame = gaussian_blur(frame, 3) # Blur 효과\n",
    "        canny_frame = canny(blur_frame, 70, 210) # Canny edge 알고리즘\n",
    "\n",
    "        vertices = np.array([[(50,height),(width/2-45, height/2+60), (width/2+45, height/2+60), (width-50,height)]], dtype=np.int32)\n",
    "        ROI_frame = region_of_interest(canny_frame, vertices) # ROI 설정\n",
    "\n",
    "        line_arr = hough_lines(ROI_frame, 1, 1 * np.pi/180, 30, 10, 20) # 허프 변환\n",
    "        line_arr = np.squeeze(line_arr)\n",
    "\n",
    "        # 기울기 구하기\n",
    "        slope_degree = (np.arctan2(line_arr[:,1] - line_arr[:,3], line_arr[:,0] - line_arr[:,2]) * 180) / np.pi\n",
    "\n",
    "        # 수평 기울기 제한\n",
    "        line_arr = line_arr[np.abs(slope_degree)<160]\n",
    "        slope_degree = slope_degree[np.abs(slope_degree)<160]\n",
    "        # 수직 기울기 제한\n",
    "        line_arr = line_arr[np.abs(slope_degree)>95]\n",
    "        slope_degree = slope_degree[np.abs(slope_degree)>95]\n",
    "        # 필터링된 직선 버리기\n",
    "        L_lines, R_lines = line_arr[(slope_degree>0),:], line_arr[(slope_degree<0),:]\n",
    "        temp = np.zeros((frame.shape[0], frame.shape[1], 3), dtype=np.uint8)\n",
    "        L_lines, R_lines = L_lines[:,None], R_lines[:,None]\n",
    "        # 왼쪽, 오른쪽 각각 대표선 구하기\n",
    "        left_fit_line = get_fitline(frame,L_lines)\n",
    "        right_fit_line = get_fitline(frame,R_lines)\n",
    "        # 대표선 그리기\n",
    "        draw_fit_line(temp, left_fit_line)\n",
    "        draw_fit_line(temp, right_fit_line)\n",
    "\n",
    "        result = weighted_img(temp, frame) # 원본 이미지에 검출된 선 overlap\n",
    "        cv2.imshow('result',result) # 결과 이미지 출력\n",
    "\n",
    "    #image = cv2.imread('slope_test.png') # 이미지 읽기\n",
    "    #image = cv2.imread('porttest1.png') # 이미지 읽기\n",
    "\n",
    "        #cv2.waitKey(0)\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "#cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이미지 파일에서 흰색만 골라내는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: cp949 -*-\n",
    "# -*- coding: utf-8 -*-  # 한글 주석쓰려면 이거 해야함\n",
    "import cv2 # opencv-python 사용\n",
    "import numpy as np\n",
    "image = cv2.imread('solidWhiteCurve.jpg') # 이미지 읽기\n",
    "mark = np.copy(image) # image 복사\n",
    "\n",
    "#  BGR 제한 값 설정\n",
    "blue_threshold = 200\n",
    "green_threshold = 200\n",
    "red_threshold = 200\n",
    "bgr_threshold = [blue_threshold, green_threshold, red_threshold]\n",
    "\n",
    "# BGR 제한 값보다 작으면 검은색으로\n",
    "thresholds = (image[:,:,0] < bgr_threshold[0]) \\\n",
    "            | (image[:,:,1] < bgr_threshold[1]) \\\n",
    "            | (image[:,:,2] < bgr_threshold[2])\n",
    "mark[thresholds] = [0,0,0]\n",
    "\n",
    "cv2.imshow('white',mark) # 흰색 추출 이미지 출력\n",
    "cv2.imshow('result',image) # 이미지 출력\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: cp949 -*-\n",
    "# -*- coding: utf-8 -*- # 한글 주석쓰려면 이거 해야함\n",
    "import cv2 # opencv 사용\n",
    "import numpy as np\n",
    "\n",
    "def region_of_interest(img, vertices, color3=(255,255,255), color1=255): # ROI 셋팅\n",
    "\n",
    "    mask = np.zeros_like(img) # mask = img와 같은 크기의 빈 이미지\n",
    "    \n",
    "    if len(img.shape) > 2: # Color 이미지(3채널)라면 :\n",
    "        color = color3\n",
    "    else: # 흑백 이미지(1채널)라면 :\n",
    "        color = color1\n",
    "        \n",
    "    # vertices에 정한 점들로 이뤄진 다각형부분(ROI 설정부분)을 color로 채움 \n",
    "    cv2.fillPoly(mask, vertices, color)\n",
    "    \n",
    "    # 이미지와 color로 채워진 ROI를 합침\n",
    "    ROI_image = cv2.bitwise_and(img, mask)\n",
    "    return ROI_image\n",
    "\n",
    "def mark_img(img, blue_threshold=200, green_threshold=200, red_threshold=200): # 흰색 차선 찾기\n",
    "\n",
    "    #  BGR 제한 값\n",
    "    bgr_threshold = [blue_threshold, green_threshold, red_threshold]\n",
    "\n",
    "    # BGR 제한 값보다 작으면 검은색으로\n",
    "    thresholds = (image[:,:,0] < bgr_threshold[0]) \\\n",
    "                | (image[:,:,1] < bgr_threshold[1]) \\\n",
    "                | (image[:,:,2] < bgr_threshold[2])\n",
    "    mark[thresholds] = [0,0,0]\n",
    "    return mark\n",
    "\n",
    "image = cv2.imread('solidWhiteCurve.jpg') # 이미지 읽기\n",
    "height, width = image.shape[:2] # 이미지 높이, 너비\n",
    "\n",
    "# 사다리꼴 모형의 Points\n",
    "vertices = np.array([[(50,height),(width/2-45, height/2+60), (width/2+45, height/2+60), (width-50,height)]], dtype=np.int32)\n",
    "roi_img = region_of_interest(image, vertices) # vertices에 정한 점들 기준으로 ROI 이미지 생성\n",
    "\n",
    "mark = np.copy(roi_img) # roi_img 복사\n",
    "mark = mark_img(roi_img) # 흰색 차선 찾기\n",
    "\n",
    "cv2.imshow('roi_white',mark) # 흰색 차선 추출 결과 출력\n",
    "cv2.imshow('result',image) # 이미지 출력\n",
    "cv2.waitKey(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: cp949 -*-\n",
    "# -*- coding: utf-8 -*-\n",
    "import cv2 # opencv 사용\n",
    "import numpy as np\n",
    "\n",
    "def region_of_interest(img, vertices, color3=(255,255,255), color1=255): # ROI 셋팅\n",
    "\n",
    "    mask = np.zeros_like(img) # mask = img와 같은 크기의 빈 이미지\n",
    "    \n",
    "    if len(img.shape) > 2: # Color 이미지(3채널)라면 :\n",
    "        color = color3\n",
    "    else: # 흑백 이미지(1채널)라면 :\n",
    "        color = color1\n",
    "        \n",
    "    # vertices에 정한 점들로 이뤄진 다각형부분(ROI 설정부분)을 color로 채움 \n",
    "    cv2.fillPoly(mask, vertices, color)\n",
    "    \n",
    "    # 이미지와 color로 채워진 ROI를 합침\n",
    "    ROI_image = cv2.bitwise_and(img, mask)\n",
    "    return ROI_image\n",
    "\n",
    "def mark_img(img, blue_threshold=200, green_threshold=200, red_threshold=200): # 흰색 차선 찾기\n",
    "\n",
    "    #  BGR 제한 값\n",
    "    bgr_threshold = [blue_threshold, green_threshold, red_threshold]\n",
    "\n",
    "    # BGR 제한 값보다 작으면 검은색으로\n",
    "    thresholds = (image[:,:,0] < bgr_threshold[0]) \\\n",
    "                | (image[:,:,1] < bgr_threshold[1]) \\\n",
    "                | (image[:,:,2] < bgr_threshold[2])\n",
    "    mark[thresholds] = [0,0,0]\n",
    "    return mark\n",
    "\n",
    "cap = cv2.VideoCapture('C:/Python_Portfolio/BlackBox_data/MDR_180912_070159.AVI') # 동영상 불러오기\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, image = cap.read()\n",
    "    height, width = image.shape[:2] # 이미지 높이, 너비\n",
    "\n",
    "    # 사다리꼴 모형의 Points\n",
    "    vertices = np.array([[(50,height),(width/2-45, height/2+60), (width/2+45, height/2+60), (width-50,height)]], dtype=np.int32)\n",
    "    roi_img = region_of_interest(image, vertices, (0,0,255)) # vertices에 정한 점들 기준으로 ROI 이미지 생성\n",
    "\n",
    "    mark = np.copy(roi_img) # roi_img 복사\n",
    "    mark = mark_img(roi_img) # 흰색 차선 찾기\n",
    "\n",
    "    # 흰색 차선 검출한 부분을 원본 image에 overlap 하기\n",
    "    color_thresholds = (mark[:,:,0] == 0) & (mark[:,:,1] == 0) & (mark[:,:,2] > 200)\n",
    "    image[color_thresholds] = [0,0,255]\n",
    "\n",
    "    cv2.imshow('results',image) # 이미지 출력\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "# Release\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: cp949 -*-\n",
    "# -*- coding: utf-8 -*- # 한글 주석쓰려면 이거 해야함\n",
    "import cv2 # opencv 사용\n",
    "import numpy as np\n",
    "cap=cv2.VideoCapture('C:/Python_Portfolio/BlackBox_data/MDR_180912_070159.AVI')\n",
    "while True:\n",
    "    #영상 읽기\n",
    "    #ret : 읽히면 T 아니면 F\n",
    "    #frame : 영상 저장 버퍼\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        gray=cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        cv2.imshow('frame',gray)\n",
    "        print(frame.shape)\n",
    "        if cv2.waitKey(10)&0xFF==ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
